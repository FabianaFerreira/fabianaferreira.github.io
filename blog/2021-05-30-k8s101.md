---
slug: k8s-101
title: Kubernetes 101
author: Fabiana Fonseca
author_title: Software Engineer @ VTEX
author_url: https://github.com/fabianaferreira
author_image_url: https://avatars.githubusercontent.com/u/19495917?s=400&u=302696fe63b0bceec347a6b90dd42bddcea1cf43&v=4
tags: [introduction, journal]
---

## Hardware
### _Node_
When it comes to hardware, a node is the smallest unit in Kubernetes. It represents a single machine in a cluster. We can think of a machine as a set of CPU and RAM resources; in that way, any machine can be replaced by another one in a cluster.

### Cluster
In Kubernetes, multiple nodes can be together, sharing resources to form a powerful machine. When we deploy an application, a cluster is smart to handle distributing work to the individual nodes. In case of adding or removing a node, the cluster will adapt and distribute work as necessary.

> In the end, it shouldn't matter to the program or the programmer in which individual machine the application is running.

### Persisted volume
Since we cannot guarantee in which node the application is running on, we cannot rely on local storage to have any data that need to be persisted; the local storage of each node can be used as a cache. Meanwhile, for instance, the CPU and RAM are at a node level, and persisted volumes are not. Instead, local or cloud drives can be attached to a cluster as a persisted volume.

> Persisted volumes provide a file system that can be mounted to the cluster.

## Software
### Containers
Programs that are running in Kubernetes are packed into containers. This concept allows programmers to create self-contained Linux execution environments. 

### _Pods_
Kubernetes does not run on containers directly; it wraps one or more containers into a higher-level structure called a pod. All the containers that are in the same pod share resources and local networks. Pods are used as the unit of replication in Kubernetes.

### _Deployments_
Despite having pods as the basic computation unit in Kubernetes, they're usually not used to be launched at a cluster directly; to do that, we use a higher-level of abstraction, called deployment, in which the main purpose is to declare how many replicas of a pod should be running. When a deployment is made at a cluster, it will automatically spin up the requested number of pods and watch them; for instance, if a pod dies, the deployment will automatically recreate it. 

### Ingress
That's how we deal with external traffic to a specific application. By default, when using Kubernetes, it automatically provides isolation between pods and outside the world. To establish communication with a service that is running in a pod, we need to open a channel for communication - we call it ingress.

> **Note for myself**: next post will go through daemonsets and side cars. 