---
slug: k8s-101
title: Kubernetes 101 [pt-br]
author: Fabiana Fonseca
author_title: Software Engineer @ VTEX
author_url: https://github.com/fabianaferreira
author_image_url: https://avatars.githubusercontent.com/u/19495917?s=400&u=302696fe63b0bceec347a6b90dd42bddcea1cf43&v=4
tags: [introduction, journal]
---

# Hardware

## _Node_
When it comes to hardware, a node is the smalled unit in Kubernets. It represents a single machine in a cluster. We can think of a machine as being a set of CPU and RAM resources and, in that way, any machine can be replaced by another one in a cluster.

## Cluster
In Kubernetes, multiple nodes can be together sharing resources in order to form a powerful machine. When we deploy an application, for instance, a cluster is smart to handle distributing work to the individual nodes. In case of adding or removing a node, the cluster will adapt and distribute work as necessary.

> In the end, it shouldn't matter to the program or the programmer in which individual machine the application is actually running.

## Persisted volume
Since we cannot guarantee in which node the application is running on, we cannot rely on local storage to have any data that need to be persisted; the local storage of each node can be used as cache. Meanwhile the CPU and RAM, for instance, are at a node level, persisted volumes are not. Instead, local or cloud drives can be attached to a cluster as a persisted volume.

> Persisted volumes provide a file system that can be mounted to the cluster.

# Software
## Containers
Programs that are running in Kubernetes are packed into containers. This concept allows programmers to create self-contained Linux execution environments. 

## _Pods_
Kubernetes does not run on contaneirs directly; it actually wraps one or more containers into a higher-level structure called pod. All the containers that are in the same pod share resources and local network. Pods are used as the unit of replication in Kubernetes.

## _Deployments_
Despite having pods as the basic computation unit in Kubernetes, they're usually not used to directly be launched at a cluster; to do that, we use a higher-level of abstraction, called deployment, which main purpose is to declare how many replicas of a pod should be running. When a deployment is made at a cluster, it will automatically spin up the requested number of pods and watch them; for instance, if a pod dies, the deployment will automatically recreate it. 

## Ingress
That's how we deal with external traffic to a specific application. By default, when using Kubernetes, it automatically provides isolation between pods and outside the world. In order to establish a communication with a service that is running in a pod, we need to open a channel for communication - we call it ingress.

> **Note for myself**: next post will go through daemonsets and side cars. 